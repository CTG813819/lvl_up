#!/bin/bash

cd /home/ubuntu/ai-backend-python

# 1. Copy the autonomous test generator to the services directory
cp autonomous_test_generator.py app/services/

# 2. Import the autonomous test generator in custody_protocol_service.py
sed -i '/from app.services.adaptive_test_system import AdaptiveTestSystem/a\
from app.services.autonomous_test_generator import autonomous_test_generator' app/services/custody_protocol_service.py

# 3. Initialize the autonomous test generator in the CustodyProtocolService.initialize method
sed -i '/self.adaptive_test_system = AdaptiveTestSystem()/a\
        self.autonomous_generator = autonomous_test_generator' app/services/custody_protocol_service.py

# 4. Replace the placeholder scenario generation with autonomous scenario generation
sed -i '/scenario = await self\.sckipit_service\.generate_olympus_treaty_scenario/a\
        # Generate autonomous test scenario\
        autonomous_scenario = await self.autonomous_generator.generate_autonomous_scenario(ai_types, difficulty)\
        scenario = autonomous_scenario["scenario"]\
        requirements = autonomous_scenario["requirements"]\
        evaluation_criteria = autonomous_scenario["evaluation_criteria"]\
        logger.info(f"ğŸ¯ Generated autonomous test scenario: {scenario}")\
        logger.info(f"ğŸ“‹ Requirements: {len(requirements)} items")\
        logger.info(f"ğŸ“Š Evaluation criteria: {len(evaluation_criteria)} categories")' app/services/custody_protocol_service.py

# 5. Replace placeholder AI response generation with autonomous AI response generation
sed -i '/test_result = await self\._get_ai_answer/a\
        # Generate autonomous AI response if answer is missing or generic\
        if not test_result.get("answer") or test_result["answer"] in ["No answer generated", "Basic response", ""]:\
            autonomous_response = await self.autonomous_generator.generate_ai_response(ai, scenario, requirements)\
            test_result["answer"] = autonomous_response\
            logger.info(f"ğŸ¤– Generated autonomous response for {ai}: {len(autonomous_response)} characters")\
        \
        # Add evaluation based on autonomous criteria\
        if not test_result.get("evaluation"):\
            score = test_result.get("score", 0)\
            if score >= 80:\
                test_result["evaluation"] = f"{ai} performed excellently with comprehensive solution and industry best practices."\
            elif score >= 60:\
                test_result["evaluation"] = f"{ai} performed well with good understanding of requirements and solid implementation."\
            elif score >= 40:\
                test_result["evaluation"] = f"{ai} performed adequately with room for improvement in implementation details."\
            else:\
                test_result["evaluation"] = f"{ai} needs improvement in understanding requirements and implementation quality."' app/services/custody_protocol_service.py

# 6. Add enhanced logging for autonomous scenarios
sed -i '/âœ… AI response for.*persisted to database/a\
            # Enhanced autonomous test result logging\
            scenario = test.get("scenario", "No scenario provided")\
            answer = test_result.get("answer", "No answer generated")\
            score = test_result.get("score", 0)\
            xp = test_result.get("xp_awarded", 0)\
            evaluation = test_result.get("evaluation", "No evaluation provided")\
            duration = test_result.get("duration", 0)\
            \
            logger.info(f"ğŸ¯ AUTONOMOUS TEST SCENARIO: {scenario}")\
            logger.info(f"ğŸ“ AI RESPONSE for {ai}: {answer[:500]}...")\
            logger.info(f"ğŸ“Š TEST RESULT for {ai}: Passed={test_result.get(\"passed\", False)}, Score={score}, XP={xp}")\
            logger.info(f"ğŸ” EVALUATION for {ai}: {evaluation}")\
            logger.info(f"â±ï¸ DURATION for {ai}: {duration} seconds")\
            logger.info(f"ğŸ† AUTONOMOUS TEST COMPLETED for {ai}")' app/services/custody_protocol_service.py

# 7. Add autonomous scenario generation for collaborative tests
sed -i '/test = await self\.generate_test/a\
        # Generate autonomous collaborative scenario\
        if test.get("scenario") in ["Basic test scenario", "Complex multi-AI collaboration challenge", ""]:\
            autonomous_scenario = await self.autonomous_generator.generate_autonomous_scenario(participants, "intermediate")\
            test["scenario"] = autonomous_scenario["scenario"]\
            test["requirements"] = autonomous_scenario["requirements"]\
            test["evaluation_criteria"] = autonomous_scenario["evaluation_criteria"]\
            logger.info(f"ğŸ¤ AUTONOMOUS COLLABORATIVE SCENARIO: {test[\"scenario\"]}")\
            logger.info(f"ğŸ‘¥ PARTICIPANTS: {participants}")\
            logger.info(f"ğŸ“‹ REQUIREMENTS: {len(test[\"requirements\"])} items")' app/services/custody_protocol_service.py

echo "âœ… Integrated autonomous test generator - No more placeholders!"